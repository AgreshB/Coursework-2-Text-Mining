{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoEncWHm5s28"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1V7EzFr6N7p"
   },
   "source": [
    "## Library installation/import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1B0__6AYci7"
   },
   "source": [
    "Install and import libraries that are used in multiple sections of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6K2gnqqfRsoS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "s7ivGrSR5NaA",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy==3.0\n",
      "  Downloading spacy-3.0.0-cp36-cp36m-macosx_10_9_x86_64.whl (12.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.4 MB 9.0 MB/s eta 0:00:011    |██████████████                  | 5.5 MB 17.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=0.20 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (51.0.0.post20201207)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (3.7.4.3)\n",
      "Requirement already satisfied: jinja2 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (2.11.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (1.17.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (4.55.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from spacy==3.0) (20.8)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp36-cp36m-macosx_10_9_x86_64.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 41.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.1\n",
      "  Using cached catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from importlib-metadata>=0.20->spacy==3.0) (3.4.0)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from packaging>=20.0->spacy==3.0) (2.4.7)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp36-cp36m-macosx_10_9_x86_64.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp36-cp36m-macosx_10_9_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 36.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: dataclasses>=0.6 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from pydantic<1.8.0,>=1.7.1->spacy==3.0) (0.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0) (2019.9.11)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Using cached spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp36-cp36m-macosx_10_9_x86_64.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 3.2 MB/s eta 0:00:01     |█████████████                   | 184 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.0\n",
      "  Downloading thinc-8.0.2-cp36-cp36m-macosx_10_9_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: contextvars<3,>=2.4 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from thinc<8.1.0,>=8.0.0->spacy==3.0) (2.4)\n",
      "Requirement already satisfied: immutables>=0.9 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from contextvars<3,>=2.4->thinc<8.1.0,>=8.0.0->spacy==3.0) (0.14)\n",
      "Collecting typer<0.4.0,>=0.3.0\n",
      "  Using cached typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from typer<0.4.0,>=0.3.0->spacy==3.0) (7.1.2)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from jinja2->spacy==3.0) (1.1.1)\n",
      "Collecting pathy\n",
      "  Using cached pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Using cached smart_open-3.0.0.tar.gz (113 kB)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107097 sha256=52bbb286e5239ead736470dfb1a3995e905be9202d9d31446c9ea1e8e0781907\n",
      "  Stored in directory: /Users/Radha/Library/Caches/pip/wheels/88/2a/d4/f2e9023989d4d4b3574f268657cb6cd23994665a038803f547\n",
      "Successfully built smart-open\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-legacy, pathy, spacy\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 cymem-2.0.5 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.0 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.2 typer-0.3.2 wasabi-0.8.2\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-3.10.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from tweepy) (1.13.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n",
      "Installing collected packages: tweepy\n",
      "Successfully installed tweepy-3.10.0\n",
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1.tar.gz (220 kB)\n",
      "\u001b[K     |████████████████████████████████| 220 kB 4.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from wordcloud) (1.17.4)\n",
      "Requirement already satisfied: pillow in /Users/Radha/anaconda3/lib/python3.6/site-packages (from wordcloud) (8.1.0)\n",
      "Requirement already satisfied: matplotlib in /Users/Radha/anaconda3/lib/python3.6/site-packages (from wordcloud) (3.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from matplotlib->wordcloud) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Radha/anaconda3/lib/python3.6/site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six in /Users/Radha/anaconda3/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.13.0)\n",
      "Building wheels for collected packages: wordcloud\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for wordcloud (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wordcloud: filename=wordcloud-1.8.1-cp36-cp36m-macosx_10_9_x86_64.whl size=161048 sha256=b862fe21a5ce6e775d638996a2d89edd668626d384656adb430aa29dd369b1d7\n",
      "  Stored in directory: /Users/Radha/Library/Caches/pip/wheels/09/7a/57/49f0c5fb0d6aaee90cb8c2d13d09a909a7b0ce42f8805fe69a\n",
      "Successfully built wordcloud\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy==3.0\n",
    "!pip install tweepy\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_S1J4oc6laA"
   },
   "source": [
    "## Configuring Twitter API keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k-DQXnYXyIO"
   },
   "source": [
    "Please note that the API keys below are the course leader's own API keys. You are allowed to use it to do some small tests, but please be careful because all students in the class now have a copy of it, and hence the limits can be easily exceeded.\n",
    "\n",
    "If your group has decided to use Twitter data, you can [apply for your own keys](https://developer.twitter.com/en/apply-for-access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0v0dZ8fCnqI"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler('fjkruboMzTLE4BLE7FmEpkWpw', 'jDobYz45Ksc3uMHoD2QnyZK60NwfRZnWIDVmyPtUGLkiOUqfGl')\n",
    "auth.set_access_token('1374773661861830658-lPZKU2qeuepRxVfWs5OxRoZd6XGzrH', '84k6xIDIMrt5mzPFLCoesD0WM9bpk8d3bAKaNonbcuT0s')\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sBB2guxczux"
   },
   "source": [
    "## Downloading of new data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5EwgFk86EfS"
   },
   "source": [
    "**IMPORTANT NOTE**: Please do not run the cell below unless intending to download a new data set.\n",
    "\n",
    "Make sure that you change the parameters.\n",
    "\n",
    "Also, check the [Tweepy API reference](https://docs.tweepy.org/en/latest/api.html) to find out about other ways through which you can retrieve tweets, e.g., by specifying usernames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSQXfQVGCpmj"
   },
   "outputs": [],
   "source": [
    "# Collect tweets\n",
    "query = \"#notoracism\" + \" -filter:retweets\"\n",
    "cutoff_date = \"2021-01-01\"\n",
    "tweets = tweepy.Cursor(api.search, q=query, lang=\"en\", since=cutoff_date).items(1000)\n",
    "\n",
    "tweets_list = [[tweet.created_at, tweet.user.screen_name, tweet.user.location, tweet.text] for tweet in tweets]\n",
    "\n",
    "tweets_df = pd.DataFrame(data=tweets_list, columns=['date', 'user', 'location', 'text'])\n",
    "\n",
    "# A good idea to save downloaded tweets as CSV\n",
    "tweets_df.to_csv ('current_set.csv', quotechar='\"', encoding='utf8', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qumfu0NwYKqR"
   },
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giyVyGPAYUTK"
   },
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K23I1qBNZ_HQ"
   },
   "source": [
    "Below we provide some code for text cleaning. However, we encourage you to think of other ways to clean your data, e.g., by removing hashtags, removing usernames, removing duplicate tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in /Users/Radha/anaconda3/lib/python3.6/site-packages (0.6.0)\n",
      "Collecting wordsegment\n",
      "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 883 kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: wordsegment\n",
      "Successfully installed wordsegment-1.3.1\n"
     ]
    }
   ],
   "source": [
    "#installing tweet-preprocessor\n",
    "!pip install tweet-preprocessor\n",
    "!pip install wordsegment\n",
    "import preprocessor as p\n",
    "from wordsegment import load, segment\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-06 10:35:34</td>\n",
       "      <td>RWDMolenbeek</td>\n",
       "      <td>Sint-Jans-Molenbeek, België</td>\n",
       "      <td>🏳️‍🌈Matchday: R.W.D.M - @KMSKDeinze 🏟E. Machte...</td>\n",
       "      <td>matchday: rwdm - e machtens stadion 20:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-06 10:24:42</td>\n",
       "      <td>motsetse_sello</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I've never seen I a white Human ever since I w...</td>\n",
       "      <td>i've never seen i a white human ever since i w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-06 07:24:48</td>\n",
       "      <td>amirjon4628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi army,This is Iranian armys\\nWe just found m...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-06 07:12:20</td>\n",
       "      <td>future_nostalgi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi army,This is Iranian armys\\nWe just found m...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-06 07:09:39</td>\n",
       "      <td>NJ7twt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Nili10724948 @MehradHidden Whenever the hater...</td>\n",
       "      <td>whenever the hater starts to hate bts does not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-06 07:06:38</td>\n",
       "      <td>Xhtly1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BunyaratwanitB @BTS_twt Hi army,This is Irani...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-06 06:57:56</td>\n",
       "      <td>_im_pudding_</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RACISM IS NOT AN OPINION  \\n#Matuschik_OUT\\n#N...</td>\n",
       "      <td>racism is not an opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-03-06 06:56:48</td>\n",
       "      <td>smartzyofficial</td>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>A Thread 👇 👇 👇 #NOtoRacism #AlperenDuymaz http...</td>\n",
       "      <td>a thread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-06 06:48:14</td>\n",
       "      <td>Mohi81933368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi army, This is Iranian armys\\nWe just found ...</td>\n",
       "      <td>hi army this is iranian armys we just found th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-03-06 06:25:25</td>\n",
       "      <td>Xhtly1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jjk_mae Hi army,This is Iranian armys\\nWe jus...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-03-06 06:24:13</td>\n",
       "      <td>Xhtly1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@FAIRYJOONLOVE Hi army,This is Iranian armys\\n...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-03-06 06:21:48</td>\n",
       "      <td>ayeeitsgen</td>\n",
       "      <td>Lost</td>\n",
       "      <td>White girl got what she deserved! Leave innoce...</td>\n",
       "      <td>white girl got what she deserved leave innocen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-03-06 06:20:40</td>\n",
       "      <td>Xhtly1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@mgfated Hi army,This is Iranian armys\\nWe jus...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-03-06 05:53:29</td>\n",
       "      <td>JlVoix</td>\n",
       "      <td>Connecticut, USA</td>\n",
       "      <td>Sadly, we are not finished with this malevolen...</td>\n",
       "      <td>sadly we are not finished with this malevolent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-03-06 04:57:06</td>\n",
       "      <td>KvSariel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RACISM AND HOMOPHOBIA AGAINST ASIAN PEOPLE AND...</td>\n",
       "      <td>racism and homophobia against asian people and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-03-06 04:26:55</td>\n",
       "      <td>Duhitzjohnny</td>\n",
       "      <td>all alone😞</td>\n",
       "      <td>I agree with black live matter but all lives m...</td>\n",
       "      <td>i agree with black live matter but all lives m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-03-06 04:23:13</td>\n",
       "      <td>_ElJohnnyBravo</td>\n",
       "      <td>Noneofyourbusinessstan</td>\n",
       "      <td>School should be a place to learn and socializ...</td>\n",
       "      <td>school should be a place to learn and socializ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-03-06 04:03:12</td>\n",
       "      <td>POWERMIKE63</td>\n",
       "      <td>CLEVELAND/PITTSBURGH/BUFFALO</td>\n",
       "      <td>Ava when you grow up I pray that you won't hav...</td>\n",
       "      <td>ava when you grow up i pray that you won't hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-03-06 03:46:12</td>\n",
       "      <td>porsche_georgia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Definitely worth giving anyone a 2nd chance ha...</td>\n",
       "      <td>definitely worth giving anyone a 2nd chance ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-03-06 03:11:11</td>\n",
       "      <td>SHE_isnotIA</td>\n",
       "      <td>SHE/HER</td>\n",
       "      <td>Don’t wait till your fav posts smth abt this. ...</td>\n",
       "      <td>dont wait till your fav posts smth abt this it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-03-06 01:34:20</td>\n",
       "      <td>The_Future_Us</td>\n",
       "      <td>Scotland, UK</td>\n",
       "      <td>@realListige #Listige this anti racism song wa...</td>\n",
       "      <td>this anti racism song was inspired by the move...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-03-06 01:14:38</td>\n",
       "      <td>DKbluth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@sammyg5150stonk @imnotacatx @barryoleary77 @R...</td>\n",
       "      <td>that's not you no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-03-06 01:12:10</td>\n",
       "      <td>teumoaengene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"LOVE US LIKE YOU LOVE OUR FOOD\"\\n\"LOVE US LIK...</td>\n",
       "      <td>\"love us like you love our food\" \"love us like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-03-06 01:07:01</td>\n",
       "      <td>drBlackketter</td>\n",
       "      <td>NW Arkansas</td>\n",
       "      <td>Can we return to the America which united peop...</td>\n",
       "      <td>can we return to the america which united peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-03-06 00:39:01</td>\n",
       "      <td>zoesot1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IG/Mehradhiddenofficial\\n#NOtoRacism \\n#Army_h...</td>\n",
       "      <td>ig/mehradhiddenofficial it is true that simila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-03-06 00:24:56</td>\n",
       "      <td>Marshal46164617</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Louis_for_ever7 #hiddenchallenge #NOtoRacism ...</td>\n",
       "      <td>just waiting for bts c`mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-03-06 00:18:37</td>\n",
       "      <td>luigicobian</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@bayern3 When are you actually gonna take prop...</td>\n",
       "      <td>when are you actually gonna take proper action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-03-06 00:08:24</td>\n",
       "      <td>Martine_MCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bowie not buying it then and wouldn’t buy it t...</td>\n",
       "      <td>bowie not buying it then and wouldnt buy it to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-03-06 00:04:23</td>\n",
       "      <td>mocyoil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you don't get out the box you've been raise...</td>\n",
       "      <td>if you don't get out the box you've been raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-03-05 23:44:26</td>\n",
       "      <td>jonasaurasme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Be responsible @bayern3, acknowledge the real ...</td>\n",
       "      <td>be responsible acknowledge the real issue prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>2021-03-05 13:44:22</td>\n",
       "      <td>goldentaelight</td>\n",
       "      <td>15 - she/her</td>\n",
       "      <td>oh my god what the fck?? This is disgusting an...</td>\n",
       "      <td>oh my god what the fck this is disgusting and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>2021-03-05 13:38:29</td>\n",
       "      <td>Meo_Xam_7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@_ngococt13_ RACISM IS NOT OPINION\\nRACISM IS ...</td>\n",
       "      <td>racism is not opinion racism is not entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>2021-03-05 13:38:25</td>\n",
       "      <td>BANGSWlFTNATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>After being accused of copying the ARMY logo, ...</td>\n",
       "      <td>after being accused of copying the army logo m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2021-03-05 12:30:28</td>\n",
       "      <td>asalsd11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Army #Racismmehradhidden  who copied the logo ...</td>\n",
       "      <td>army who copied the logo a few days ago &amp;amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>2021-03-05 12:18:27</td>\n",
       "      <td>The_Future_Us</td>\n",
       "      <td>Scotland, UK</td>\n",
       "      <td>@bbcintroducing This anti-racism song, was ins...</td>\n",
       "      <td>this anti-racism song was inspired by the move...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2021-03-05 12:12:16</td>\n",
       "      <td>madwrld_con</td>\n",
       "      <td>Hell</td>\n",
       "      <td>❗️PLEASE SPREAD AWARENESS ❗️\\nSo in this video...</td>\n",
       "      <td>please spread awareness so in this video it cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2021-03-05 12:10:14</td>\n",
       "      <td>The_Future_Us</td>\n",
       "      <td>Scotland, UK</td>\n",
       "      <td>@AntiRacismDay Thank you for the work you do. ...</td>\n",
       "      <td>thank you for the work you do this is a song w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2021-03-05 11:42:25</td>\n",
       "      <td>Ftm81531580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@PJMINBESTESTBOY @BigHitEnt Arrrmy heeelp\\n#Ar...</td>\n",
       "      <td>arrrmy heeelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2021-03-05 11:41:38</td>\n",
       "      <td>Ftm81531580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@zseven07_ @BigHitEnt Arrrmy heeelp\\n#Army_hel...</td>\n",
       "      <td>arrrmy heeelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2021-03-05 11:40:57</td>\n",
       "      <td>Ftm81531580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@97_Kookphoria @BigHitEnt Arrrmy help\\n#Army_h...</td>\n",
       "      <td>arrrmy help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2021-03-05 11:38:25</td>\n",
       "      <td>Ftm81531580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@BigHitEnt arrrmy heelp\\n#Army_help #ARMYSelca...</td>\n",
       "      <td>arrrmy heelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2021-03-05 11:18:09</td>\n",
       "      <td>btskim09990857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Army Please block and report\\nRacism has to st...</td>\n",
       "      <td>army please block and report racism has to stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2021-03-05 11:14:21</td>\n",
       "      <td>Lara99768256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi army,This is Iranian armys\\nWe just found m...</td>\n",
       "      <td>hi armythis is iranian armys we just found meh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2021-03-05 10:57:40</td>\n",
       "      <td>Lachimo09478135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As long as there's no action made, we will not...</td>\n",
       "      <td>as long as there's no action made we will not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2021-03-05 10:54:35</td>\n",
       "      <td>Sports_Guy321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some good news @IanWright0 👏👏\\n\\nEA Sports ban...</td>\n",
       "      <td>some good news ea sports bans irish fifa playe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2021-03-05 10:43:02</td>\n",
       "      <td>kimvany_1995</td>\n",
       "      <td>Bangtan's Heart 💜</td>\n",
       "      <td>@Chanh1304 RACISM IS NOT AN OPINION\\n#NOtoRaci...</td>\n",
       "      <td>racism is not an opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2021-03-05 10:38:38</td>\n",
       "      <td>Brazil2017_Rap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Vega_RSA @akashhebbarcfc8 here for you too du...</td>\n",
       "      <td>here for you too dude one day this trolls we h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2021-03-05 10:37:20</td>\n",
       "      <td>Bangswifties_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attention to all the kpop fandoms:\\nHis fans (...</td>\n",
       "      <td>attention to all the kpop fandoms: his fans (t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2021-03-05 10:17:21</td>\n",
       "      <td>R1ghtTh1nk</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>@OliviaGoldhill White people stealing Black pe...</td>\n",
       "      <td>white people stealing black people's vaccines ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2021-03-05 10:04:04</td>\n",
       "      <td>Bangswifties_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He just wants attention but he will regret thi...</td>\n",
       "      <td>he just wants attention but he will regret thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2021-03-05 10:02:38</td>\n",
       "      <td>Juno2431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Aerikwin_twt RACISM IS NOT AN OPINION\\nWE WAN...</td>\n",
       "      <td>racism is not an opinion we want fair media</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2021-03-05 09:55:56</td>\n",
       "      <td>Bangswifties_13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Iranian Armys will always support BTS and ARMY...</td>\n",
       "      <td>iranian armys will always support bts and army...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2021-03-05 09:48:56</td>\n",
       "      <td>feveryone4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mk. So this is why I personally think that BLM...</td>\n",
       "      <td>mk so this is why i personally think that blm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2021-03-05 09:11:37</td>\n",
       "      <td>JRPMusicnLorde</td>\n",
       "      <td>Hologram album link below</td>\n",
       "      <td>@deathbysupercut I feel really sorry... 💔💔💔 #R...</td>\n",
       "      <td>i feel really sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2021-03-05 09:06:11</td>\n",
       "      <td>Mitrashadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WHAT THE HEL!!! \\nhe want to challenge BTS 😂😂😂...</td>\n",
       "      <td>what the hel he want to challenge bts so funny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2021-03-05 08:49:40</td>\n",
       "      <td>jessiii_01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zum Ende der Woche:\\n\\nRACISM IS NOT AN OPINIO...</td>\n",
       "      <td>zum ende der woche: racism is not an opinion w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2021-03-05 08:39:48</td>\n",
       "      <td>MinMintlia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The most powerful fandom in the world😎😏       ...</td>\n",
       "      <td>the most powerful fandom in the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2021-03-05 08:21:12</td>\n",
       "      <td>Lachimo09478135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As long as there's no action made, we will not...</td>\n",
       "      <td>as long as there's no action made we will not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2021-03-05 08:08:06</td>\n",
       "      <td>Mitrashadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>He is so fucked up\\nReport himm\\n#Army_help #N...</td>\n",
       "      <td>he is so fucked up report himm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2021-03-05 08:07:31</td>\n",
       "      <td>Mitrashadow</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Koreaboo Hi guys I'm iranian army\\nJust repor...</td>\n",
       "      <td>hi guys i'm iranian army just report and block...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date             user                      location  \\\n",
       "0    2021-03-06 10:35:34     RWDMolenbeek   Sint-Jans-Molenbeek, België   \n",
       "1    2021-03-06 10:24:42   motsetse_sello                           NaN   \n",
       "2    2021-03-06 07:24:48      amirjon4628                           NaN   \n",
       "3    2021-03-06 07:12:20  future_nostalgi                           NaN   \n",
       "4    2021-03-06 07:09:39           NJ7twt                           NaN   \n",
       "5    2021-03-06 07:06:38           Xhtly1                           NaN   \n",
       "6    2021-03-06 06:57:56     _im_pudding_                           NaN   \n",
       "7    2021-03-06 06:56:48  smartzyofficial                Lagos, Nigeria   \n",
       "8    2021-03-06 06:48:14     Mohi81933368                           NaN   \n",
       "9    2021-03-06 06:25:25           Xhtly1                           NaN   \n",
       "10   2021-03-06 06:24:13           Xhtly1                           NaN   \n",
       "11   2021-03-06 06:21:48       ayeeitsgen                          Lost   \n",
       "12   2021-03-06 06:20:40           Xhtly1                           NaN   \n",
       "13   2021-03-06 05:53:29           JlVoix              Connecticut, USA   \n",
       "14   2021-03-06 04:57:06         KvSariel                           NaN   \n",
       "15   2021-03-06 04:26:55     Duhitzjohnny                    all alone😞   \n",
       "16   2021-03-06 04:23:13   _ElJohnnyBravo        Noneofyourbusinessstan   \n",
       "17   2021-03-06 04:03:12      POWERMIKE63  CLEVELAND/PITTSBURGH/BUFFALO   \n",
       "18   2021-03-06 03:46:12  porsche_georgia                           NaN   \n",
       "19   2021-03-06 03:11:11      SHE_isnotIA                       SHE/HER   \n",
       "20   2021-03-06 01:34:20    The_Future_Us                  Scotland, UK   \n",
       "21   2021-03-06 01:14:38          DKbluth                           NaN   \n",
       "22   2021-03-06 01:12:10     teumoaengene                           NaN   \n",
       "23   2021-03-06 01:07:01    drBlackketter                   NW Arkansas   \n",
       "24   2021-03-06 00:39:01          zoesot1                           NaN   \n",
       "25   2021-03-06 00:24:56  Marshal46164617                           NaN   \n",
       "26   2021-03-06 00:18:37      luigicobian                           NaN   \n",
       "27   2021-03-06 00:08:24      Martine_MCM                           NaN   \n",
       "28   2021-03-06 00:04:23          mocyoil                           NaN   \n",
       "29   2021-03-05 23:44:26     jonasaurasme                           NaN   \n",
       "..                   ...              ...                           ...   \n",
       "110  2021-03-05 13:44:22   goldentaelight                  15 - she/her   \n",
       "111  2021-03-05 13:38:29        Meo_Xam_7                           NaN   \n",
       "112  2021-03-05 13:38:25  BANGSWlFTNATION                           NaN   \n",
       "113  2021-03-05 12:30:28         asalsd11                           NaN   \n",
       "114  2021-03-05 12:18:27    The_Future_Us                  Scotland, UK   \n",
       "115  2021-03-05 12:12:16      madwrld_con                          Hell   \n",
       "116  2021-03-05 12:10:14    The_Future_Us                  Scotland, UK   \n",
       "117  2021-03-05 11:42:25      Ftm81531580                           NaN   \n",
       "118  2021-03-05 11:41:38      Ftm81531580                           NaN   \n",
       "119  2021-03-05 11:40:57      Ftm81531580                           NaN   \n",
       "120  2021-03-05 11:38:25      Ftm81531580                           NaN   \n",
       "121  2021-03-05 11:18:09   btskim09990857                           NaN   \n",
       "122  2021-03-05 11:14:21     Lara99768256                           NaN   \n",
       "123  2021-03-05 10:57:40  Lachimo09478135                           NaN   \n",
       "124  2021-03-05 10:54:35    Sports_Guy321                           NaN   \n",
       "125  2021-03-05 10:43:02     kimvany_1995             Bangtan's Heart 💜   \n",
       "126  2021-03-05 10:38:38   Brazil2017_Rap                           NaN   \n",
       "127  2021-03-05 10:37:20  Bangswifties_13                           NaN   \n",
       "128  2021-03-05 10:17:21       R1ghtTh1nk             San Francisco, CA   \n",
       "129  2021-03-05 10:04:04  Bangswifties_13                           NaN   \n",
       "130  2021-03-05 10:02:38         Juno2431                           NaN   \n",
       "131  2021-03-05 09:55:56  Bangswifties_13                           NaN   \n",
       "132  2021-03-05 09:48:56       feveryone4                           NaN   \n",
       "133  2021-03-05 09:11:37   JRPMusicnLorde    Hologram album link below    \n",
       "134  2021-03-05 09:06:11      Mitrashadow                           NaN   \n",
       "135  2021-03-05 08:49:40       jessiii_01                           NaN   \n",
       "136  2021-03-05 08:39:48       MinMintlia                           NaN   \n",
       "137  2021-03-05 08:21:12  Lachimo09478135                           NaN   \n",
       "138  2021-03-05 08:08:06      Mitrashadow                           NaN   \n",
       "139  2021-03-05 08:07:31      Mitrashadow                           NaN   \n",
       "\n",
       "                                                  text  \\\n",
       "0    🏳️‍🌈Matchday: R.W.D.M - @KMSKDeinze 🏟E. Machte...   \n",
       "1    I've never seen I a white Human ever since I w...   \n",
       "2    Hi army,This is Iranian armys\\nWe just found m...   \n",
       "3    Hi army,This is Iranian armys\\nWe just found m...   \n",
       "4    @Nili10724948 @MehradHidden Whenever the hater...   \n",
       "5    @BunyaratwanitB @BTS_twt Hi army,This is Irani...   \n",
       "6    RACISM IS NOT AN OPINION  \\n#Matuschik_OUT\\n#N...   \n",
       "7    A Thread 👇 👇 👇 #NOtoRacism #AlperenDuymaz http...   \n",
       "8    Hi army, This is Iranian armys\\nWe just found ...   \n",
       "9    @jjk_mae Hi army,This is Iranian armys\\nWe jus...   \n",
       "10   @FAIRYJOONLOVE Hi army,This is Iranian armys\\n...   \n",
       "11   White girl got what she deserved! Leave innoce...   \n",
       "12   @mgfated Hi army,This is Iranian armys\\nWe jus...   \n",
       "13   Sadly, we are not finished with this malevolen...   \n",
       "14   RACISM AND HOMOPHOBIA AGAINST ASIAN PEOPLE AND...   \n",
       "15   I agree with black live matter but all lives m...   \n",
       "16   School should be a place to learn and socializ...   \n",
       "17   Ava when you grow up I pray that you won't hav...   \n",
       "18   Definitely worth giving anyone a 2nd chance ha...   \n",
       "19   Don’t wait till your fav posts smth abt this. ...   \n",
       "20   @realListige #Listige this anti racism song wa...   \n",
       "21   @sammyg5150stonk @imnotacatx @barryoleary77 @R...   \n",
       "22   \"LOVE US LIKE YOU LOVE OUR FOOD\"\\n\"LOVE US LIK...   \n",
       "23   Can we return to the America which united peop...   \n",
       "24   IG/Mehradhiddenofficial\\n#NOtoRacism \\n#Army_h...   \n",
       "25   @Louis_for_ever7 #hiddenchallenge #NOtoRacism ...   \n",
       "26   @bayern3 When are you actually gonna take prop...   \n",
       "27   Bowie not buying it then and wouldn’t buy it t...   \n",
       "28   If you don't get out the box you've been raise...   \n",
       "29   Be responsible @bayern3, acknowledge the real ...   \n",
       "..                                                 ...   \n",
       "110  oh my god what the fck?? This is disgusting an...   \n",
       "111  @_ngococt13_ RACISM IS NOT OPINION\\nRACISM IS ...   \n",
       "112  After being accused of copying the ARMY logo, ...   \n",
       "113  Army #Racismmehradhidden  who copied the logo ...   \n",
       "114  @bbcintroducing This anti-racism song, was ins...   \n",
       "115  ❗️PLEASE SPREAD AWARENESS ❗️\\nSo in this video...   \n",
       "116  @AntiRacismDay Thank you for the work you do. ...   \n",
       "117  @PJMINBESTESTBOY @BigHitEnt Arrrmy heeelp\\n#Ar...   \n",
       "118  @zseven07_ @BigHitEnt Arrrmy heeelp\\n#Army_hel...   \n",
       "119  @97_Kookphoria @BigHitEnt Arrrmy help\\n#Army_h...   \n",
       "120  @BigHitEnt arrrmy heelp\\n#Army_help #ARMYSelca...   \n",
       "121  Army Please block and report\\nRacism has to st...   \n",
       "122  Hi army,This is Iranian armys\\nWe just found m...   \n",
       "123  As long as there's no action made, we will not...   \n",
       "124  Some good news @IanWright0 👏👏\\n\\nEA Sports ban...   \n",
       "125  @Chanh1304 RACISM IS NOT AN OPINION\\n#NOtoRaci...   \n",
       "126  @Vega_RSA @akashhebbarcfc8 here for you too du...   \n",
       "127  Attention to all the kpop fandoms:\\nHis fans (...   \n",
       "128  @OliviaGoldhill White people stealing Black pe...   \n",
       "129  He just wants attention but he will regret thi...   \n",
       "130  @Aerikwin_twt RACISM IS NOT AN OPINION\\nWE WAN...   \n",
       "131  Iranian Armys will always support BTS and ARMY...   \n",
       "132  Mk. So this is why I personally think that BLM...   \n",
       "133  @deathbysupercut I feel really sorry... 💔💔💔 #R...   \n",
       "134  WHAT THE HEL!!! \\nhe want to challenge BTS 😂😂😂...   \n",
       "135  Zum Ende der Woche:\\n\\nRACISM IS NOT AN OPINIO...   \n",
       "136  The most powerful fandom in the world😎😏       ...   \n",
       "137  As long as there's no action made, we will not...   \n",
       "138  He is so fucked up\\nReport himm\\n#Army_help #N...   \n",
       "139  @Koreaboo Hi guys I'm iranian army\\nJust repor...   \n",
       "\n",
       "                                        text_processed  \n",
       "0            matchday: rwdm - e machtens stadion 20:45  \n",
       "1    i've never seen i a white human ever since i w...  \n",
       "2    hi armythis is iranian armys we just found meh...  \n",
       "3    hi armythis is iranian armys we just found meh...  \n",
       "4    whenever the hater starts to hate bts does not...  \n",
       "5    hi armythis is iranian armys we just found meh...  \n",
       "6                             racism is not an opinion  \n",
       "7                                             a thread  \n",
       "8    hi army this is iranian armys we just found th...  \n",
       "9    hi armythis is iranian armys we just found meh...  \n",
       "10   hi armythis is iranian armys we just found meh...  \n",
       "11   white girl got what she deserved leave innocen...  \n",
       "12   hi armythis is iranian armys we just found meh...  \n",
       "13   sadly we are not finished with this malevolent...  \n",
       "14   racism and homophobia against asian people and...  \n",
       "15   i agree with black live matter but all lives m...  \n",
       "16   school should be a place to learn and socializ...  \n",
       "17   ava when you grow up i pray that you won't hav...  \n",
       "18   definitely worth giving anyone a 2nd chance ha...  \n",
       "19   dont wait till your fav posts smth abt this it...  \n",
       "20   this anti racism song was inspired by the move...  \n",
       "21                                   that's not you no  \n",
       "22   \"love us like you love our food\" \"love us like...  \n",
       "23   can we return to the america which united peop...  \n",
       "24   ig/mehradhiddenofficial it is true that simila...  \n",
       "25                          just waiting for bts c`mon  \n",
       "26   when are you actually gonna take proper action...  \n",
       "27   bowie not buying it then and wouldnt buy it to...  \n",
       "28   if you don't get out the box you've been raise...  \n",
       "29   be responsible acknowledge the real issue prop...  \n",
       "..                                                 ...  \n",
       "110  oh my god what the fck this is disgusting and ...  \n",
       "111  racism is not opinion racism is not entertainment  \n",
       "112  after being accused of copying the army logo m...  \n",
       "113  army who copied the logo a few days ago &amp; ...  \n",
       "114  this anti-racism song was inspired by the move...  \n",
       "115  please spread awareness so in this video it cl...  \n",
       "116  thank you for the work you do this is a song w...  \n",
       "117                                      arrrmy heeelp  \n",
       "118                                      arrrmy heeelp  \n",
       "119                                        arrrmy help  \n",
       "120                                       arrrmy heelp  \n",
       "121    army please block and report racism has to stop  \n",
       "122  hi armythis is iranian armys we just found meh...  \n",
       "123  as long as there's no action made we will not ...  \n",
       "124  some good news ea sports bans irish fifa playe...  \n",
       "125                           racism is not an opinion  \n",
       "126  here for you too dude one day this trolls we h...  \n",
       "127  attention to all the kpop fandoms: his fans (t...  \n",
       "128  white people stealing black people's vaccines ...  \n",
       "129  he just wants attention but he will regret thi...  \n",
       "130        racism is not an opinion we want fair media  \n",
       "131  iranian armys will always support bts and army...  \n",
       "132  mk so this is why i personally think that blm ...  \n",
       "133                                i feel really sorry  \n",
       "134  what the hel he want to challenge bts so funny...  \n",
       "135  zum ende der woche: racism is not an opinion w...  \n",
       "136              the most powerful fandom in the world  \n",
       "137  as long as there's no action made we will not ...  \n",
       "138                     he is so fucked up report himm  \n",
       "139  hi guys i'm iranian army just report and block...  \n",
       "\n",
       "[140 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comment if not using pre saved data set \n",
    "tweets_df = pd.read_csv('current_set.csv', quotechar='\"', encoding='utf8')\n",
    "cleaned_tweets = []\n",
    "\n",
    "# include hastags and remove urls and emojis and mentions\n",
    "#p.set_options(p.OPT.URL, p.OPT.EMOJI,p.OPT.MENTION)\n",
    "for tweet in tweets_df['text']:\n",
    "    cleaned_tweets.append(p.clean(tweet))\n",
    "\n",
    "# adding back to data frame\n",
    "tweets_df['text_processed'] = cleaned_tweets\n",
    "\n",
    "#removing punctuation\n",
    "tweets_df['text_processed'] = tweets_df['text_processed'].map(lambda x: re.sub('[,\\\\.!?]', '', x))\n",
    "\n",
    "# Remove unnecessary line breaks\n",
    "tweets_df['text_processed'] = tweets_df['text_processed'].map(lambda x: re.sub(r\"\\n\", '', x))\n",
    "\n",
    "# Convert the titles to lowercase\n",
    "tweets_df['text_processed'] = tweets_df['text_processed'].map(lambda x: x.lower())\n",
    "\n",
    "#removing hastags for now \n",
    "tweets_df['text_processed'] = tweets_df['text_processed'].map(lambda x: re.sub(r\"#(\\w+)\",\"\",x))\n",
    "\n",
    "#removing extra whitespaces \n",
    "tweets_df['text_processed'] = tweets_df['text_processed'].map(lambda x: ' '.join(x.split()))\n",
    "\n",
    "\n",
    "display(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22qj0jq3YklZ"
   },
   "source": [
    "## Exploration using a word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IIh30BjaWji"
   },
   "source": [
    "Generating a word cloud is one way by which you can check whether your data needs any further cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KqxuMbjk8EkA"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# join the words of the different tweets together into one string\n",
    "long_string = ' '.join(unique_tweets)\n",
    "new_long_string = ' '.join(set(long_string.split(\" \")))\n",
    "\n",
    "# create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=1000, contour_width=3, contour_color='steelblue')\n",
    "\n",
    "# generate a word cloud\n",
    "wordcloud.generate(new_long_string)\n",
    "\n",
    "# visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HQyNo3FYYuED"
   },
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GwAZb_l-7C-L"
   },
   "outputs": [],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tfx5EMNw_pIw"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# Do you want to modify this by adding more stop words?\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "  for sentence in sentences:\n",
    "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "  return [[word for word in simple_preprocess(str(doc)) \n",
    "    if word not in stop_words] for doc in texts]\n",
    "\n",
    "\n",
    "data = tweets_df.text_processed.values.tolist()\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "# remove stop words\n",
    "data_words = remove_stopwords(data_words)\n",
    "\n",
    "# create a dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "\n",
    "# create a corpus\n",
    "texts = data_words\n",
    "\n",
    "# convert the corpus into a BoW representation\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOb8cNW3PVfk"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# set number of topics\n",
    "num_topics = 5\n",
    "\n",
    "# build an LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics)\n",
    "\n",
    "# print keywords in each topic\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RPtA2Yg7Hnm"
   },
   "outputs": [],
   "source": [
    "# visualise the topics\n",
    "!pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWueCQawPlXn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "LDAvis_data_filepath = os.path.join('./'+str(num_topics))\n",
    "\n",
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "with open(LDAvis_data_filepath, 'wb') as f:\n",
    "  pickle.dump(LDAvis_prepared, f)\n",
    "\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "  LDAvis_prepared = pickle.load(f)\n",
    "\n",
    "pyLDAvis.save_html(LDAvis_prepared, './'+ str(num_topics) +'.html')\n",
    "\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7UoGTRZY1pg"
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3RLsS3Ac8v7"
   },
   "source": [
    "This implementation is based on the lexicon- and rule-based [VADER](https://github.com/cjhutto/vaderSentiment) sentiment analysis tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gas4oUUIY8iF"
   },
   "outputs": [],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hK8WbOHbA78"
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "for tweet_text in unique_tweets:\n",
    "    vs = analyzer.polarity_scores(tweet_text)\n",
    "    print(tweet_text + '\\t' + str(vs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT11HUQBY47n"
   },
   "source": [
    "# Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TcanVP2udd24"
   },
   "source": [
    "This implementation is based on [spaCy's model](https://spacy.io/models/en#en_core_web_trf) using contextualised embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUWgWiLZYaBS"
   },
   "outputs": [],
   "source": [
    "!pip install spacy-transformers\n",
    "!python -m spacy download en_core_web_trf\n",
    "import spacy\n",
    "import en_core_web_trf\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAvsa90Gpwna"
   },
   "outputs": [],
   "source": [
    "for tweet_text in unique_tweets:\n",
    "  doc = nlp(tweet_text)\n",
    "  print(tweet_text)\n",
    "  for ne in doc.ents:\n",
    "    print('\\tNE found: ', ne.start_char, ne.end_char, ne.label_, tweet_text[ne.start_char:ne.end_char])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Ub0m8zoZfH"
   },
   "source": [
    "# Named Entity Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqLYLoM7ecLP"
   },
   "source": [
    "This implementation is based on [spaCy Entity Linker](https://github.com/egerber/spacy-entity-linker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvKRih-dYEDL"
   },
   "outputs": [],
   "source": [
    "!pip install spacy-entity-linker\n",
    "!python -m spacyEntityLinker \"download_knowledge_base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7bxxYpFcuoz"
   },
   "outputs": [],
   "source": [
    "from spacyEntityLinker import EntityLinker\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.factory(\n",
    "   \"entityLinker\"\n",
    ")\n",
    "def create_linker(nlp, name):\n",
    "  return EntityLinker()\n",
    "\n",
    "#add to pipeline\n",
    "nlp.add_pipe('entityLinker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nnZZ0t32oCgZ"
   },
   "outputs": [],
   "source": [
    "for tweet_text in unique_tweets:\n",
    "  doc = nlp(tweet_text)\n",
    "  print(tweet_text)\n",
    "  all_linked_entities = doc._.linkedEntities\n",
    "  all_linked_entities.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Coursework 2: SMA.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
